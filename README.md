# BansrChat 技术架构

本文档详细介绍 BansrChat 大模型语音对话框架的技术架构、模块设计及工作流程。

## 系统架构概览

BansrChat 由四个核心模块组成，形成完整的语音交互闭环：

1. **语音识别模块** (ASR) - 将用户语音转换为文本
2. **大语言模型模块** (LLM) - 处理文本并生成回复
3. **语音合成模块** (TTS) - 将文本回复转换为语音
4. **唤醒词检测模块** (可选) - 监听特定唤醒词

整体架构图：

```
+----------------+     +----------------+     +----------------+
|                |     |                |     |                |
|  语音输入设备   +---->+   语音识别     +---->+  大语言模型    |
|   (麦克风)      |     |    (ASR)      |     |    (LLM)      |
|                |     |                |     |                |
+----------------+     +----------------+     +----------------+
                                                      |
+----------------+     +----------------+             |
|                |     |                |             |
|  语音输出设备   +<----+   语音合成     +<------------+
|   (扬声器)      |     |    (TTS)      |
|                |     |                |
+----------------+     +----------------+

         ^
         |
+----------------+
|                |
|   唤醒词检测    |  (可选)
|    (Vosk)      |
|                |
+----------------+
```

## 核心模块详解

### 1. ASR.py - 语音识别模块

#### 主要功能：
- 通过麦克风捕获用户语音
- 实时将语音转换为文本
- 检测停顿和结束语，自动结束录音
- 集成大模型和TTS调用逻辑

#### 关键技术点：
- 使用讯飞语音听写WebSocket API
- 实现流式识别和WPGS（Word Partial Grammar Spotting）
- 静音检测和语音活动检测
- WebSocket连接管理和重连机制

### 2. spark_api.py - 大语言模型模块

#### 主要功能：
- 连接讯飞星火大模型API
- 处理用户文本输入
- 获取大模型生成的回复
- 管理对话历史上下文

#### 关键技术点：
- WebSocket连接和认证
- 流式接收模型回复
- 对话历史管理
- 错误处理和重试机制

### 3. tts_api.py - 语音合成模块

#### 主要功能：
- 将文本转换为自然语音
- 支持普通语音合成和超拟人语音合成
- 流式播放合成的语音

#### 关键技术点：
- 使用讯飞在线语音合成API
- 流式接收和播放音频数据
- 使用ffmpeg处理音频流
- 支持不同的语音合成参数调整

### 4. wake_up.py - 唤醒词检测模块

#### 主要功能：
- 离线监听特定唤醒词
- 唤醒词触发后启动完整对话流程

#### 关键技术点：
- 使用Vosk开源语音识别库
- 本地唤醒词检测，无需联网
- 低资源占用的持续监听机制

## 数据流和工作流程

### 标准对话流程

1. **语音输入阶段**
   - 麦克风捕获声音
   - 实时转发给语音识别服务
   - 实时显示识别结果
   - 检测到停顿后结束录音

2. **大模型处理阶段**
   - 将完整识别文本发送给星火大模型
   - 星火大模型根据对话历史和当前输入生成回复
   - 流式返回响应内容

3. **语音合成阶段**
   - 将大模型回复文本发送给语音合成服务
   - 流式接收合成的音频数据
   - 使用ffmpeg实时播放合成的语音

4. **循环阶段**
   - 语音播放完成后，回到第一步，等待新的语音输入
   - 或者检测到退出关键词，结束程序

### 唤醒模式工作流程

1. **等待唤醒阶段**
   - 持续监听环境声音
   - 使用Vosk进行本地语音识别
   - 匹配预设的唤醒词

2. **唤醒后流程**
   - 检测到唤醒词后播放欢迎语
   - 切换到标准对话流程
   - 对话结束后回到等待唤醒状态

## 性能优化策略

- **预连接机制**: 提前建立WebSocket连接，减少响应延迟
- **服务预初始化**: 程序启动时预先初始化各服务客户端
- **流式处理**: 全链路采用流式处理，实现低延迟交互
- **资源管理**: 适时释放不需要的连接和资源，优化内存使用
- **静音优化**: 在静音期间减少处理，降低CPU占用

## 扩展性设计

BansrChat 的模块化设计使其易于扩展：

- **支持其他语音识别引擎**: 可以替换ASR模块以使用其他厂商的API
- **支持其他大语言模型**: 修改spark_api.py可以集成其他LLM服务
- **自定义TTS引擎**: 可以替换或扩展TTS模块以使用其他语音合成服务
- **多模态支持**: 架构设计便于未来扩展到包含图像处理等多模态能力


# BansrChat 使用指南

本项目是由Claude、DeepSeek等大模型共同生成，本人小白，仅提供思路。并整合、修改代码而成。欢迎各位大神、专家完善本项目。

## 运行模式

BansrChat 支持两种运行模式：

1. **直接对话模式** - 无需唤醒词，直接进行语音对话
2. **唤醒词模式** - 需要先说出唤醒词，才能开始对话

## 直接对话模式

### 启动方法

```bash
python ASR.py
```

### 交互流程

1. 程序启动后，会立即开始监听您的语音
2. 对着麦克风说话，系统会实时显示识别结果
3. 当您停止说话后（静音2秒），系统会自动结束录音
4. 星火大模型会处理您的问题并生成回复
5. 系统会通过语音合成播放回复内容
6. 回复播放完成后，系统会自动开始下一轮对话

### 结束对话

在任意对话中说出以下关键词之一可以结束程序：
- "停止"
- "退出"
- "结束程序"
- "关闭"
- "拜拜"
- "再见"

## 唤醒词模式

### 启动方法

```bash
python WakeUp.py
```

### 交互流程

1. 程序启动后，会等待您说出唤醒词
2. 默认唤醒词为：“一二三”（可在.env中自定义，建议选择常用词汇，Vosk的本地语言模型性能有限）
3. 当检测到唤醒词后，系统会播放欢迎语
4. 进入对话模式，操作方式与直接对话模式相同
5. 对话结束后（使用关键词退出或自然结束），系统会回到等待唤醒状态

## 常见问题解决

### 语音识别问题

如果您遇到语音识别不准确的问题：
- 确保使用较好的麦克风
- 尽量在安静的环境中使用
- 清晰地发音
- 调整 `.env` 文件中的识别相关参数

### 语音合成问题

如果语音合成效果不佳：
- 尝试调整 `.env` 文件中的 `TTS_VOICE`、`TTS_SPEED`、`TTS_VOLUME` 等参数
- 考虑启用超拟人语音合成模式（设置 `USE_SUPER_TTS=true`）

### 系统响应慢或无响应

如果系统响应速度慢：
- 检查网络连接
- 确认讯飞API密钥配置正确
- 查看控制台输出是否有错误信息

## 高级用法

### 自定义唤醒词

编辑 `.env` 文件中的 `WAKE_WORDS` 参数，多个唤醒词用逗号分隔。例如：

```
WAKE_WORDS=你好助手,小助手醒醒,开始对话
```

### 自定义大模型系统提示词

编辑 `.env` 文件中的 `SPARK_SYSTEM_PROMPT` 参数可以设置大模型的系统提示词，例如：

```
SPARK_SYSTEM_PROMPT=你是一个专业的助手，擅长回答简短清晰的问题
```

### 静音检测灵敏度调整

如果您发现系统过早结束录音或无法检测到您的语音输入完成，可以在代码中调整以下参数：

- `ASR.py` 文件中的 `SILENCE_THRESHOLD` 变量：调整静音检测的阈值
- `ASR.py` 文件中的 `MAX_SILENCE_TIME` 变量：调整静音持续多久后结束录音
